{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbbf2c3",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7806c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (1212, 832), y_train.shape (1212, 1), X_test.shape (776, 832)\n",
      "              x0            x1           x2             x3          x4  \\\n",
      "id                                                                       \n",
      "0   14168.823171  10514.380717  3316.149698   94230.695124  102.386606   \n",
      "1   17757.037554           NaN  4101.016273   92959.527633         NaN   \n",
      "2   14226.656663  11029.642499          NaN  124055.600561  100.542483   \n",
      "3    8766.012436   7384.202998  2147.308418  100157.719990  104.855061   \n",
      "4   13801.016418  13269.493652  3408.316953   92048.527786  103.759758   \n",
      "\n",
      "            x5            x6            x7            x8         x9  ...  \\\n",
      "id                                                                   ...   \n",
      "0    92.677127  11108.748199  10866.505510  10837.622093  10.227734  ...   \n",
      "1    99.855168  10013.959449  10826.607494  10076.101597  11.436970  ...   \n",
      "2    92.860892           NaN  10492.342868           NaN  10.810076  ...   \n",
      "3   101.929026  10050.049932  10499.521099  10525.030989  10.092109  ...   \n",
      "4    95.789235   9667.353978  10750.783106  10618.800750  12.006773  ...   \n",
      "\n",
      "            x822          x823        x824        x825        x826  \\\n",
      "id                                                                   \n",
      "0            NaN  12352.094085  846.014651  105.132144  102.112809   \n",
      "1            NaN  16198.071494  776.084467  106.385590  103.472030   \n",
      "2   10329.704431  13976.063780  737.040332  103.671234  109.458246   \n",
      "3   10008.251395   6212.127347  329.044233  105.084488  104.858546   \n",
      "4   10095.782015  13772.061493         NaN         NaN  100.369834   \n",
      "\n",
      "           x827      x828         x829         x830          x831  \n",
      "id                                                                 \n",
      "0   2090.004260  2.691845  1234.374109  1000.784475   9285.751272  \n",
      "1   2474.051881  2.287976          NaN  1012.626705  11750.284764  \n",
      "2   2656.083281  2.843706   888.353607  1048.810385   9553.922728  \n",
      "3   1097.785204  2.732257   927.752967  1048.357330           NaN  \n",
      "4   2693.053231  2.702908  1471.354073  1071.284484   9423.533063  \n",
      "\n",
      "[5 rows x 832 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "data_dir = Path(\"data\")\n",
    "\n",
    "X_test = data_dir / \"X_test.csv\"\n",
    "y_train = data_dir / \"y_train.csv\"\n",
    "X_train = data_dir / \"X_train.csv\"\n",
    "\n",
    "X_test = pd.read_csv(X_test, index_col=\"id\")\n",
    "X_test.index = X_test.index.astype(int)\n",
    "\n",
    "y_train = pd.read_csv(y_train, index_col=\"id\")\n",
    "y_train.index = y_train.index.astype(int)\n",
    "\n",
    "X_train = pd.read_csv(X_train, index_col=\"id\")\n",
    "X_train.index = X_train.index.astype(int)\n",
    "\n",
    "print(f\"X_train.shape {X_train.shape}, y_train.shape {y_train.shape}, X_test.shape {X_test.shape}\")\n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7d5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOYxJREFUeJzt3Qd8FHX+//FPaAktAYIkoEBo0rEEhQA2jAaMCIIURQXlxIIoRTniCYiCRFCaUpQHBhEB4XeI7UABEUUDUgQ7RVoQEjglhHIJJfN/fL73373d1E3YZHeS1/PxGGBnZme/+82See+3zARYlmUJAACADZXxdQEAAAAKiyADAABsiyADAABsiyADAABsiyADAABsiyADAABsiyADAABsiyADAABsiyADAABsiyAD/H8vvPCCBAQEFMtr3XzzzWZx+PLLL81r/9///V+xvP7AgQMlIiJC/Nnp06flb3/7m4SHh5u6GTZsmK+LVGpofev/h4JasGCBee7WrVsL/H8AKCyCDEokxy9UxxIUFCR16tSRmJgYmTlzppw6dcorr3PkyBHzC3/Hjh3ib/y5bJ54+eWXzc/x8ccfl3fffVceeOCBXMNnfos/njD1/a1cuTLf/aZOnWrew9q1a3PdZ968eWafjz76yMulBPxfOV8XAChKL774ojRo0EDOnz8vycnJpuVDv9nryUF/6bdp08a57/PPPy+jR48ucFgYP368ad24+uqrPX7e559/LkUtr7LpiS8zM1P82RdffCHt27eXcePG5bpPz549pXHjxm6tOBp87r77brPNISwsTPwxyNxzzz3So0ePPPfr16+fPPvss7J48WKJjo7OcR/dFhoaKl27dvVK2f7zn/9IuXKcHmAPfFJRoukv9rZt2zofx8XFmRPknXfeKXfddZf8+uuvUrFiRbNNf3EX9S/vs2fPSqVKlaRChQriS+XLlxd/d+zYMWnRokWe+2gQdQ2j//73v02Q0XX333//JZfhzJkzUrlyZfElbUm85ZZbZMWKFTJnzhwJDAx02/7HH3/IV199JYMHD76kn6sG23PnzpnWS10Au6BrCaVO586dZcyYMXLw4EFZtGhRnmNk1qxZI506dZJq1apJlSpVpGnTpvLcc8+Zbdq6c91115l/P/TQQ85uDO0OUdqd0apVK9m2bZvceOONJsA4npvb+ICLFy+afXRciJ5ANWwlJSW57aMtLDrGJSvXY+ZXtpzGyOhJe+TIkVK3bl1zstT3+uqrr4plWW776XGefPJJ0y2i70/3bdmypaxevdrjgDJo0CDTSqInzKuuukreeeedbOOF9u/fL59++qmz7AcOHJDC0J/zE088Yd6PhlZtuejdu3e24zm6Izds2GD2r1WrllxxxRXO7bNmzZKGDRuaY1x//fXy9ddf5/hzzMjIMK1I2lKkdaP1OWrUKLPetQ61vvV9O95fTj9TBw1lJ0+eNPWR1dKlS00I6d+/v3msP7MOHTqY96lljYyMzHHslePn+N5775mfn5bV8TPMOkbG0zp0DeyPPvqo2S84OFgefPBBOXHiRK7vryB1B2RFiwxKJR1voYFBu3geeeSRHPf5+eefTcuNfrvXLir9xbp371755ptvzPbmzZub9WPHjjXfhm+44QazXk8iDn/++adpFdLuAT0Z5dfFMXHiRHMS+fvf/25O+NOnTzfdCTrOxdFy5AlPyuZKw4qGpvXr15uQoV1Rn332menS0G/806ZNc9t/48aNpoVAT25Vq1Y144569eolhw4dMievvLos9MSv9agnUe32W758uTmJp6amytNPP23KrmNihg8fboKEhit12WWXSWFs2bJFvv32W/Mz0OPpyVdbNrQcv/zyiwmYrvQ96Wtp3WnYULq/llfrUculx9AuoerVq7uFHQ0UWo9aP1rv+l5+/PFHU3+7d+92jonR96cDmTUQ6X6qUaNGub4H7SbTlibtQnLtMlO6rn79+tKxY0fzeMaMGaYMGmy0hUWDjoaOTz75RGJjY92eq62Ty5YtM++tZs2auQ4AL2gd6vE0/GsY2rVrl9lXw5AjpObE07oDsrGAEighIUGbEawtW7bkuk9ISIh1zTXXOB+PGzfOPMdh2rRp5vHx48dzPYYeX/fR18vqpptuMtvmzp2b4zZdHNavX2/2vfzyy620tDTn+mXLlpn1M2bMcK6rX7++NWDAgHyPmVfZ9Pl6HIeVK1eafSdMmOC23z333GMFBARYe/fuda7T/SpUqOC2bufOnWb966+/buVl+vTpZr9FixY51507d86KioqyqlSp4vbetXyxsbFWQejPSo+vP0uHs2fPZtsvMTHR7Ldw4cJsn5lOnTpZFy5ccK7PyMiwQkNDreuuu846f/68c/2CBQvM/q51/u6771plypSxvv76a7fX08+A7vvNN98411WuXDnHn2NuevfubQUFBVknT550rvvtt9/McePi4nJ9v1q/rVq1sjp37uy2Xp+nZf3555+zvdal1mFkZKR5XYfJkyeb9R9++GGun9eC1B3giq4llFraVZTX7CX9Rqk+/PDDQg+M1VYc7drxlDbBawuHgw4GrV27tvzrX/+SoqTHL1u2rDz11FNu67U1RM9rq1atcluvrUSuLQjaaqVdCPv27cv3dbTb7N5773Wu03Ed+ro6UFe7dbzNtSVLB31rK5l2XejPd/v27dn21xY6rQsHnUqsz9H1rmOotMVDW2RcaeuStiQ0a9bMjNdxLNqdqbTFq7C0RS89Pd20hLm2xjjKktP71e4c7ZLSlqSc3utNN92U7zikwtRh1vE62pqkdZfX57go6w4lG0EGpZaeOF1DQ1Z9+/Y1zfXaBaBdQtqsrs3wBQk1l19+eYEG9jZp0sTtsTbD6wmjsONDPKXN/jqoNGt96InFsd1VvXr1sh1DT+r5jYPQ4+h7LFOmjEev4w3anaXdRI6xP9qFol1H2pWlJ/mstLsra5mV6+wopSfmrF0xe/bsMV2SenzX5corrzTbtbuwsLSLskaNGs7wopYsWWLGGOkYFwftQtLZXjr+SPfX19euHU/eq7fqMOvnWL80aCDP63NclHWHko0xMiiVDh8+bH4BZz05Zf0WqrNB9JugDrLUgZDvv/+++YaoY2tcv7XndQxvy22MgQ4U9qRM3pDb62QdGOwPhg4dKgkJCWbafVRUlISEhJg61GCaUyi9lJ+ZHq9169Zmen9ONAgUlrZw9OnTx0ydT0lJMeOR9OQ/efJk5z46AFnHmejg8tmzZ5vwoM/T9+8agAr6Xgtah/5WdyjZCDIolXSwpdIL5OVFWw5uvfVWs+gvWL32xz/+8Q8TbrR7xdtXAtYTU9ZgoANjXacYa8uHfhPOSlsOdFaNQ0HKpoNF9YJr2tXm2irz22+/Obd7gx7nhx9+MCct11YZb7+OK52xM2DAAHnttdec67SLJqc6zK3MSn8OOg3a4cKFC6aFwfVno91tO3fuNJ+X/Oq/MJ8d7UKaO3euCdQ6q0uP4dpN989//tO0xOhAbddp2hpCirMO9XPsWlfa+nn06FG54447cn2NgtQd4IquJZQ6OlPjpZdeMs3qrmMLsvrrr7+yrXNcWM4xHdRxjRFPT4r5Wbhwodu4HT2B6AnA9UJn+gt/06ZNZkaKa3dC1mnaBSmbnmC0ReeNN95wW68zRvSk4q0Lrenr6IUJ9UTsGghef/110/2gYzaKovUoa0uRvp6+X0/odYh0Jpa2hGhZHXTactauNG0x0Vleum9O3TOOWVCOn09BPzfa1andWXrZAK1DrS/XWVP6XvXn5freNGxd6oyfgtbhW2+9ZcbSOGjXltZdXp+jgtQd4IoWGZRoOkhVv+3rL1FtjtcQo9eG0W/ZemXfvC78pdOXtWtJp6zq/tpHr831euLQa8s4QoUOeNRvydqSoSendu3aeTz2ICsd06DH1gHCWl6dfq3dX65TxHXMjgacLl26mF/+v//+uzmxZZ2+W5CydevWzXyD1tYmPfHpuAvtPtOBztqdkNfU4ILQQaBvvvmmmW6t19fRk7K+F53Sru81rzFLhaVT6LUFTrtDdGBrYmKiaX3Ka5q4Kx3jpNOItXtFuxW1zrWO9LozWi+urQc6rV/HUT322GOm1U6Dh57s9TOo67WlxHGBRr2+i5ZDW/p0fJL+XPTnkxd9rfvuu8+0DDo+o670s6rH08+G7qefWb3+jX6GtCWsuOpQQ7a2rGhd6fRr/X+jn2vt9spNQeoOcOM2hwkoIRzTQB2LThcODw+3brvtNjOV2XWab27Tr9etW2d1797dqlOnjnm+/n3vvfdau3fvdnueTilt0aKFVa5cObfpzjq1tGXLljmWL7fp10uWLDFTaWvVqmVVrFjRTD8+ePBgtue/9tprZqp2YGCg1bFjR2vr1q3ZjplX2bJOv1anTp2yhg8fbt5n+fLlrSZNmlhTpkyxMjMz3fbT4wwZMiRbmXKbFp5VSkqK9dBDD1k1a9Y09dq6descp4h7a/r1iRMnnK+nU7xjYmLMtOWs5c1vyv7MmTPNc7TOr7/+ejMdWKcZd+nSxW0/nXb8yiuvmJ+97lu9enWz3/jx47NNnb7xxhvNz1lf19Op2DpdWvfXY+t7y2r+/PnmZ6fbmzVrZt5X1s92Xj9Hx7ZLqcMNGzZYgwcPNu9d9+/fv7/1559/ur1GTp9XT+sOcBWgf7hHGwBAfnScj86q0QvU5dQdAqB4MEYGAPKhA1uzfufT8Uw6jsof76wNlCa0yABAPvTS+nprAr3Uv44L0YvAzZ8/31z/Rsf6+PomoEBpxmBfAMiHDkrW65joPaW0FUYHZetVmOPj4wkxgI/RIgMAAGyLMTIAAMC2CDIAAMC2ypWGKZJHjhwxF9ristcAANiDjnzRK53rBSOz3mi2VAUZDTHcbAwAAHvS26+43oqj1AUZxyXPtSKCg4N9XRwAAOCBtLQ00xCR361LSnyQcXQnaYghyAAAYC/5DQthsC8AALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALCtcr4uAACUNhGjP813nwPxscVSFsDuaJEBAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC25dMgc/HiRRkzZow0aNBAKlasKI0aNZKXXnpJLMty7qP/Hjt2rNSuXdvsEx0dLXv27PFlsQEAgJ/waZB55ZVXZM6cOfLGG2/Ir7/+ah5PnjxZXn/9dec++njmzJkyd+5c2bx5s1SuXFliYmIkPT3dl0UHAACl/cq+3377rXTv3l1iY/97BcuIiAhZsmSJfPfdd87WmOnTp8vzzz9v9lMLFy6UsLAwWblypfTr18+XxQcAAKW5RaZDhw6ybt062b17t3m8c+dO2bhxo3Tt2tU83r9/vyQnJ5vuJIeQkBBp166dJCYm5njMjIwMSUtLc1sAAEDJ5NMWmdGjR5ug0axZMylbtqwZMzNx4kTp37+/2a4hRmkLjCt97NiW1aRJk2T8+PHFUHoAAFCqW2SWLVsm7733nixevFi2b98u77zzjrz66qvm78KKi4uTkydPOpekpCSvlhkAAPgPn7bIPPvss6ZVxjHWpXXr1nLw4EHTqjJgwAAJDw8361NSUsysJQd9fPXVV+d4zMDAQLMAAICSz6ctMmfPnpUyZdyLoF1MmZmZ5t86LVvDjI6jcdCuKJ29FBUVVezlBQAA/sWnLTLdunUzY2Lq1asnLVu2lO+//16mTp0qDz/8sNkeEBAgw4YNkwkTJkiTJk1MsNHrztSpU0d69Ojhy6IDAIDSHmT0ejEaTJ544gk5duyYCSiPPvqouQCew6hRo+TMmTMyePBgSU1NlU6dOsnq1aslKCjIl0UHAAB+IMByvYxuCaRdUTplWwf+BgcH+7o4ACARoz/Nd58D8f+9vhZQWqV5eP7mXksAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2fBpkIiIiJCAgINsyZMgQsz09Pd38OzQ0VKpUqSK9evWSlJQUXxYZAAD4EZ8GmS1btsjRo0edy5o1a8z63r17m7+HDx8uH3/8sSxfvlw2bNggR44ckZ49e/qyyAAAwI+U8+WLX3bZZW6P4+PjpVGjRnLTTTfJyZMnZf78+bJ48WLp3Lmz2Z6QkCDNmzeXTZs2Sfv27X1UagAA4C/8ZozMuXPnZNGiRfLwww+b7qVt27bJ+fPnJTo62rlPs2bNpF69epKYmJjrcTIyMiQtLc1tAQAAJZPfBJmVK1dKamqqDBw40DxOTk6WChUqSLVq1dz2CwsLM9tyM2nSJAkJCXEudevWLfKyAwCAUh5ktBupa9euUqdOnUs6TlxcnOmWcixJSUleKyMAAPAvPh0j43Dw4EFZu3atrFixwrkuPDzcdDdpK41rq4zOWtJtuQkMDDQLAAAo+fyiRUYH8daqVUtiY2Od6yIjI6V8+fKybt0657pdu3bJoUOHJCoqykclBQAA/sTnLTKZmZkmyAwYMEDKlftfcXR8y6BBg2TEiBFSo0YNCQ4OlqFDh5oQw4wloGhEjP40330OxP/vCwcASGkPMtqlpK0sOlspq2nTpkmZMmXMhfB0NlJMTIzMnj3bJ+UEAAD+x+dB5vbbbxfLsnLcFhQUJLNmzTILAACAX46RAQAAKAyCDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2fB5k//vhD7r//fgkNDZWKFStK69atZevWrc7tlmXJ2LFjpXbt2mZ7dHS07Nmzx6dlBgAA/sGnQebEiRPSsWNHKV++vKxatUp++eUXee2116R69erOfSZPniwzZ86UuXPnyubNm6Vy5coSExMj6enpviw6AADwA+V8+eKvvPKK1K1bVxISEpzrGjRo4NYaM336dHn++eele/fuZt3ChQslLCxMVq5cKf369fNJuQEAgH/waYvMRx99JG3btpXevXtLrVq15JprrpF58+Y5t+/fv1+Sk5NNd5JDSEiItGvXThITE3M8ZkZGhqSlpbktAACgZPJpi8y+fftkzpw5MmLECHnuuedky5Yt8tRTT0mFChVkwIABJsQobYFxpY8d27KaNGmSjB8/vljKDyBnEaM/zXefA/GxxVIWACWbT1tkMjMz5dprr5WXX37ZtMYMHjxYHnnkETMeprDi4uLk5MmTziUpKcmrZQYAAP7Dp0FGZyK1aNHCbV3z5s3l0KFD5t/h4eHm75SUFLd99LFjW1aBgYESHBzstgAAgJLJp0FGZyzt2rXLbd3u3bulfv36zoG/GljWrVvn3K5jXnT2UlRUVLGXFwAA+BefjpEZPny4dOjQwXQt9enTR7777jt56623zKICAgJk2LBhMmHCBGnSpIkJNmPGjJE6depIjx49fFl0AABQ2oPMddddJx988IEZ1/Liiy+aoKLTrfv37+/cZ9SoUXLmzBkzfiY1NVU6deokq1evlqCgIF8WHQAAlPYgo+68806z5EZbZTTk6AIAAOBXtygAAAAoLIIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLZ/fogAA7CJi9Kf57nMgPrZYygLgv2iRAQAAtkWQAQAAtkWQAQAAtsUYGQA+wXgTAN5AiwwAALAtggwAALAtggwAALAtggwAALAtBvsC8FvFOSDYk9cC4H9okQEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALbFdWQAlHhcIwYouWiRAQAAtkWQAQAApSvI7Nu3z/slAQAAKI4g07hxY7nllltk0aJFkp6eLoX1wgsvSEBAgNvSrFkz53Y99pAhQyQ0NFSqVKkivXr1kpSUlEK/HgAAKFkKFWS2b98ubdq0kREjRkh4eLg8+uij8t133xWqAC1btpSjR486l40bNzq3DR8+XD7++GNZvny5bNiwQY4cOSI9e/Ys1OsAAICSp1BB5uqrr5YZM2aYYPH222+bANKpUydp1aqVTJ06VY4fP+7xscqVK2fCkGOpWbOmWX/y5EmZP3++OV7nzp0lMjJSEhIS5Ntvv5VNmzYVptgAAKCEuaTBvhpCtIVEW0xeeeUV2bt3rzzzzDNSt25defDBB03Ayc+ePXukTp060rBhQ+nfv78cOnTIrN+2bZucP39eoqOjnftqt1O9evUkMTHxUooNAABKiEsKMlu3bpUnnnhCateubVpONMT8/vvvsmbNGtNa07179zyf365dO1mwYIGsXr1a5syZI/v375cbbrhBTp06JcnJyVKhQgWpVq2a23PCwsLMttxkZGRIWlqa2wIAAEqmQl0QT0OLdvPs2rVL7rjjDlm4cKH5u0yZ/+aiBg0amIASERGR53G6du3q/LeOudFgU79+fVm2bJlUrFixMEWTSZMmyfjx4wv1XAAAUApaZLT15L777pODBw/KypUr5c4773SGGIdatWqZMS4Foa0vV155pemi0vEy586dk9TUVLd9dNaSbstNXFycGV/jWJKSkgr47gAAQIlukdFxLfnRbqEBAwYU6LinT582XVMPPPCAGdxbvnx5WbdunZl2rbQFSMfQREVF5XqMwMBAswAAgJKvUEFGu5X0ui69e/d2W6+Dfs+ePetxgNExNd26dTPdSTqmZty4cVK2bFm59957JSQkRAYNGmSmeNeoUUOCg4Nl6NChJsS0b9++MMUGAAAlTJnCjkNxTJPO2p308ssve3ycw4cPm9DStGlT6dOnj7nwnU6tvuyyy8z2adOmmW4rbZG58cYbTZfSihUrClNkAABQAhWqRUa7d3RAb1basuKYPu2JpUuX5rk9KChIZs2aZRYAAACvtMhoy8sPP/yQbf3OnTtNqwoAAIDfBhntDnrqqadk/fr1cvHiRbN88cUX8vTTT0u/fv28X0oAAABvdS299NJLcuDAAbn11lvN1X1VZmamuZpvQcbIAAAAFHuQ0anV77//vgk02p2kF69r3bq1GSMDAADg10HGQS9epwsAAIBtgoyOidFbEOjF6o4dO2a6lVzpeBkAAAC/DDI6qFeDTGxsrLRq1UoCAgK8XzIAAICiCDJ6/Re9saPeKBIAAMBW0691sG/jxo29XxoAAICiDjIjR46UGTNmiGVZhXk6AACA77qWNm7caC6Gt2rVKmnZsqW5S7Ur7ocEAAD8NshUq1ZN7r77bu+XBoDfixj9qa+LAACXFmQSEhIK8zQAAADfj5FRFy5ckLVr18qbb74pp06dMuuOHDkip0+f9mb5AAAAvNsic/DgQenSpYscOnRIMjIy5LbbbpOqVavKK6+8Yh7PnTu3MIcFAAAongvitW3b1txnKTQ01Llex8088sgjhTkkABQKY3aA0q1QQebrr7+Wb7/91lxPxlVERIT88ccf3iobAACA98fI6L2V9H5LWR0+fNh0MQEAAPhtkLn99ttl+vTpzsd6ryUd5Dtu3DhuWwAAAPy7a+m1116TmJgYadGihaSnp8t9990ne/bskZo1a8qSJUu8X0oAKGU8GftzID62WMoClLggc8UVV5iBvnrzyB9++MG0xgwaNEj69+8vFStW9H4pAQAAvBVkzBPLlZP777+/sE8HAADwTZBZuHBhntsffPDBwpYHAACg6K8j4+r8+fNy9uxZMx27UqVKBBkApRbXtQFsMGvpxIkTbouOkdm1a5d06tSJwb4AAMD/77WUVZMmTSQ+Pj5baw0AAIDfBxnHAGC9cSQAAIDfjpH56KOP3B5bliVHjx6VN954Qzp27OitsgEAAHg/yPTo0cPtsV7Z97LLLpPOnTubi+UBAAD4bZDRey0BAACUqDEyAAAAft8iM2LECI/3nTp1amFeAgAAoGiCzPfff28WvRBe06ZNzbrdu3dL2bJl5dprr3UbO+MpnbodFxdnpm877qytN6QcOXKkuadTRkaGuVHl7NmzJSwsrDDFBgAAJUyhgky3bt2katWq8s4770j16tXNOr0w3kMPPSQ33HCDCR8FsWXLFnnzzTelTZs2buuHDx8un376qSxfvlxCQkLkySeflJ49e8o333xTmGIDAIASplBjZHRm0qRJk5whRum/J0yYUOBZS3pVYL1r9rx589yOd/LkSZk/f77pmtLZUJGRkZKQkCDffvutbNq0qTDFBgAAJUyhgkxaWpocP34823pdd+rUqQIda8iQIRIbGyvR0dFu67dt22a6rlzXN2vWTOrVqyeJiYm5Hk+7oLR8rgsAACiZChVk7r77btONtGLFCjl8+LBZ/vnPf8qgQYNM14+ndOzL9u3bTetOVsnJyeYmlNWqVXNbr+NjdFtu9FjaDeVY6tatW8B3BwAASvQYmblz58ozzzwj9913n2k1MQcqV84EmSlTpnh0jKSkJDOwd82aNRIUFCTeogOGXWdVaYsMYQYAgJKpUEGmUqVKZvaQhpbff//drGvUqJFUrlzZ42No19GxY8fcZjldvHhRvvrqK3Org88++0zOnTsnqampbq0yKSkpEh4enutxAwMDzQIAAEq+S7ognt5fSRe987WGGL3nkqduvfVW+fHHH2XHjh3OpW3btmbgr+Pf5cuXl3Xr1jmfs2vXLjl06JBERUVdSrEBAEBpbpH5888/pU+fPrJ+/XpzrZg9e/ZIw4YNTdeSzjzyZOaSTt9u1aqV2zoNQ6Ghoc71ejztJqpRo4YEBwfL0KFDTYhp3759YYoNAABKmEK1yOj1XbS1RFtHtJvJoW/fvrJ69WqvFW7atGly5513Sq9eveTGG280XUo6wBgAAKDQLTKff/65GcNyxRVXuK3XLqaDBw8Wuma//PJLt8c6CHjWrFlmAQAA8EqLzJkzZ9xaYhz++usvBtoCAAD/DjJ6G4KFCxc6H+s4mczMTJk8ebLccsst3iwfAACAd7uWNLDorKOtW7eaKdKjRo2Sn3/+2bTIcB8kAADg1y0yOqtI73bdqVMn6d69u+lq0iv66h2x9XoyAAAAftkio1fy7dKli7m67z/+8Y+iKRUAAEBRtMjotOsffvihoE8DAADwjzEy999/v8yfP1/i4+O9XyIAgNdEjP40330OxMcW23EAvwgyFy5ckLffflvWrl0rkZGR2e6xNHXqVG+VDwAAwDtBZt++fRIRESE//fST82aPOujXlU7FBgAA8Lsgo1fu1ZtE6j2WHLckmDlzpoSFhRVV+QAAALwz2Dfr3a1XrVplpl4DAADY5joyuQUbAAAAvw0yOv4l6xgYxsQAAABbjJHRFpiBAwc6bwyZnp4ujz32WLZZSytWrPBuKQEAAC41yAwYMCDb9WQAAABsEWQSEhKKriQAAADFOdgXAADAlwgyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAACgdNxrCfCViNGf5rvPgfjYYikLYKf/F0BJR4sMAACwLYIMAACwLYIMAACwLZ+OkZkzZ45ZDhw4YB63bNlSxo4dK127djWP09PTZeTIkbJ06VLJyMiQmJgYmT17toSFhfmy2ABQojDWBnbm0xaZK664QuLj42Xbtm2ydetW6dy5s3Tv3l1+/vlns3348OHy8ccfy/Lly2XDhg1y5MgR6dmzpy+LDAAA/IhPW2S6devm9njixImmhWbTpk0m5MyfP18WL15sAo5KSEiQ5s2bm+3t27f3UakBAIC/8JsxMhcvXjRdSGfOnJGoqCjTSnP+/HmJjo527tOsWTOpV6+eJCYm5noc7YJKS0tzWwAAQMnk8+vI/Pjjjya46HiYKlWqyAcffCAtWrSQHTt2SIUKFaRatWpu++v4mOTk5FyPN2nSJBk/fnwxlBywF8ZBACiJfN4i07RpUxNaNm/eLI8//rgMGDBAfvnll0IfLy4uTk6ePOlckpKSvFpeAADgP3zeIqOtLo0bNzb/joyMlC1btsiMGTOkb9++cu7cOUlNTXVrlUlJSZHw8PBcjxcYGGgWAABQ8vm8RSarzMxMM85FQ0358uVl3bp1zm27du2SQ4cOma4oAAAAn7bIaDeQXjNGB/CeOnXKzFD68ssv5bPPPpOQkBAZNGiQjBgxQmrUqCHBwcEydOhQE2KYsQQAAHweZI4dOyYPPvigHD161ASXNm3amBBz2223me3Tpk2TMmXKSK9evdwuiAeUFN66GSYDeQGUVj4NMnqdmLwEBQXJrFmzzAIAAOD3Y2QAAAA8RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC25fNbFAAA4M/XaYJ/o0UGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYVjlfFwAAUDJEjP40330OxMcWS1lQetAiAwAAbIsgAwAAbIsgAwAAbIsxMkAJGHcA2AXjaOBttMgAAADbIsgAAADbIsgAAADbIsgAAADb8mmQmTRpklx33XVStWpVqVWrlvTo0UN27drltk96eroMGTJEQkNDpUqVKtKrVy9JSUnxWZkBAID/8GmQ2bBhgwkpmzZtkjVr1sj58+fl9ttvlzNnzjj3GT58uHz88ceyfPlys/+RI0ekZ8+eviw2AADwEz6dfr169Wq3xwsWLDAtM9u2bZMbb7xRTp48KfPnz5fFixdL586dzT4JCQnSvHlzE37at2/vo5IDAAB/4FdjZDS4qBo1api/NdBoK010dLRzn2bNmkm9evUkMTExx2NkZGRIWlqa2wIAAEomvwkymZmZMmzYMOnYsaO0atXKrEtOTpYKFSpItWrV3PYNCwsz23IbdxMSEuJc6tatWyzlBwAApTjI6FiZn376SZYuXXpJx4mLizMtO44lKSnJa2UEAAD+xS9uUfDkk0/KJ598Il999ZVcccUVzvXh4eFy7tw5SU1NdWuV0VlLui0ngYGBZgEAACWfT1tkLMsyIeaDDz6QL774Qho0aOC2PTIyUsqXLy/r1q1zrtPp2YcOHZKoqCgflBgAAPiTcr7uTtIZSR9++KG5loxj3IuObalYsaL5e9CgQTJixAgzADg4OFiGDh1qQgwzluDvuNkjAJTwIDNnzhzz98033+y2XqdYDxw40Px72rRpUqZMGXMhPJ2RFBMTI7Nnz/ZJeQEAgH8p5+uupfwEBQXJrFmzzAIAAOCXs5YAAAAKiiADAABsiyADAABsiyADAABsiyADAABsiyADAABsyy9uUQD400XqDsTHeuU4AICiR4sMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLa4jgxKDa7sApQf/3+FAiwwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtLogHn/O3C1v5W3kAALmjRQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANiWT68j89VXX8mUKVNk27ZtcvToUfnggw+kR48ezu2WZcm4ceNk3rx5kpqaKh07dpQ5c+ZIkyZNfFlsFADXZAEAlNgWmTNnzshVV10ls2bNynH75MmTZebMmTJ37lzZvHmzVK5cWWJiYiQ9Pb3YywoAAPyPT1tkunbtapacaGvM9OnT5fnnn5fu3bubdQsXLpSwsDBZuXKl9OvXr5hLCwAA/I3fjpHZv3+/JCcnS3R0tHNdSEiItGvXThITE3N9XkZGhqSlpbktAACgZPLbey1piFHaAuNKHzu25WTSpEkyfvz4Ii8fAKBoMLYOJaJFprDi4uLk5MmTziUpKcnXRQIAAKUtyISHh5u/U1JS3NbrY8e2nAQGBkpwcLDbAgAASia/DTINGjQwgWXdunXOdTreRWcvRUVF+bRsAADAP/h0jMzp06dl7969bgN8d+zYITVq1JB69erJsGHDZMKECea6MRpsxowZI3Xq1HG71gwAACi9fBpktm7dKrfccovz8YgRI8zfAwYMkAULFsioUaPMtWYGDx5sLojXqVMnWb16tQQFBfmw1KWDJ4PtDsTHFktZAKCo8LvO/nwaZG6++WZzvZjcBAQEyIsvvmgWAAAA24yRAQAAyA9BBgAA2JbfXhAP/n+xKS5aBQDwNVpkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbRFkAACAbXHTSBvx5CaNB+Jji6UsAAD4A1pkAACAbRFkAACAbRFkAACAbTFGxiZjXwAAvlFSxydGlJD3RYsMAACwLYIMAACwLYIMAACwLcbIXIKS0r8IAPCP8wHnlYKjRQYAANgWQQYAANgWQQYAANgWY2QAALDRNcOK89pjETYYs0OLDAAAsC2CDAAAsC2CDAAAsC1bjJGZNWuWTJkyRZKTk+Wqq66S119/Xa6//nqxg+K+jxL3bQIAlCZ+3yLz/vvvy4gRI2TcuHGyfft2E2RiYmLk2LFjvi4aAADwMb8PMlOnTpVHHnlEHnroIWnRooXMnTtXKlWqJG+//baviwYAAHzMr4PMuXPnZNu2bRIdHe1cV6ZMGfM4MTHRp2UDAAC+59djZP7973/LxYsXJSwszG29Pv7tt99yfE5GRoZZHE6ePGn+TktL83r5MjPOev2YAADYSVoRnF9dj2tZln2DTGFMmjRJxo8fn2193bp1fVIeAABKspDpRXv8U6dOSUhIiD2DTM2aNaVs2bKSkpLitl4fh4eH5/icuLg4MzjYITMzU/766y8JDQ2VgIAAt6Sn4SYpKUmCg4OL8F2UbNSjd1CP3kE9egf16B3U46XRlhgNMXXq1MlzP78OMhUqVJDIyEhZt26d9OjRwxlM9PGTTz6Z43MCAwPN4qpatWq5voZ+uPiAXTrq0TuoR++gHr2DevQO6rHw8mqJsUWQUdq6MmDAAGnbtq25dsz06dPlzJkzZhYTAAAo3fw+yPTt21eOHz8uY8eONRfEu/rqq2X16tXZBgADAIDSx++DjNJupNy6kgpLu5/0IntZu6FQMNSjd1CP3kE9egf16B3UY/EIsPKb1wQAAOCn/PqCeAAAAHkhyAAAANsiyAAAANsiyAAAANsqVUEmPj7eXN132LBhznXp6ekyZMgQc+XfKlWqSK9evbJdSbi0e+GFF0y9uS7NmjVzbqcOPffHH3/I/fffb+qqYsWK0rp1a9m6datzu46910sN1K5d22zXG6Tu2bPHp2X2NxEREdk+j7roZ1DxefSM3sduzJgx0qBBA/NZa9Sokbz00ktu97Xh8+gZvfqsnlfq169v6qlDhw6yZcsW53bqsYhZpcR3331nRUREWG3atLGefvpp5/rHHnvMqlu3rrVu3Tpr69atVvv27a0OHTr4tKz+Zty4cVbLli2to0ePOpfjx487t1OHnvnrr7+s+vXrWwMHDrQ2b95s7du3z/rss8+svXv3OveJj4+3QkJCrJUrV1o7d+607rrrLqtBgwbWf/7zH5+W3Z8cO3bM7bO4Zs0aPfNa69evN9v5PHpm4sSJVmhoqPXJJ59Y+/fvt5YvX25VqVLFmjFjhnMfPo+e6dOnj9WiRQtrw4YN1p49e8zvzODgYOvw4cNmO/VYtEpFkDl16pTVpEkT8wvvpptucgaZ1NRUq3z58uY/sMOvv/5qfikmJib6sMT+Rf9TXnXVVTluow499/e//93q1KlTrtszMzOt8PBwa8qUKW71GxgYaC1ZsqSYSmk/+v+5UaNGpv74PHouNjbWevjhh93W9ezZ0+rfv7/5N59Hz5w9e9YqW7asCYSurr32Wusf//gH9VgMSkXXkjYzx8bGmuY8V9u2bZPz58+7rdcuk3r16kliYqIPSuq/tBlUb9zVsGFD6d+/vxw6dMispw4999FHH5lbbfTu3Vtq1aol11xzjcybN8+5ff/+/ebq1a51qfcZadeuHXWZi3PnzsmiRYvk4YcfNt1LfB49p90fet+63bt3m8c7d+6UjRs3SteuXc1jPo+euXDhgummCwoKcluvXUhan9Rj0bPFlX0vxdKlS2X79u1u/ZUO+uHSG1Nmvamk3v5At+G/9D/cggULpGnTpnL06FEZP3683HDDDfLTTz9RhwWwb98+mTNnjrl/2HPPPWc+k0899ZSpP72fmKO+st5+g7rM3cqVKyU1NVUGDhxoHvN59Nzo0aPN3Zk16JUtW9acjCdOnGi+qCg+j56pWrWqREVFmfFFzZs3N/WzZMkSE1IaN25MPRaDEh1k9NbpTz/9tKxZsyZbWobnHN/QVJs2bUyw0UFty5YtM9864Bm9c7u2yLz88svmsbbIaBicO3euCTIouPnz55vPp7YWomD0/+97770nixcvlpYtW8qOHTvMgFWtSz6PBfPuu++aVsHLL7/chMJrr71W7r33XtNCiKJXoruW9EN07Ngx86EqV66cWTZs2CAzZ840/9ZErE3T+o3Olc5wCA8P91m5/Z1+273yyitl7969pp6oQ8/ojIUWLVq4rdNvcI5uOkd9ZZ1hQ13m7ODBg7J27Vr529/+5lzH59Fzzz77rGmV6devn5k998ADD8jw4cNl0qRJZjufR8/pjC89t5w+fdp8gf7uu+9MF6d2xVOPRa9EB5lbb71VfvzxR/NNw7HoN2JtOnX8u3z58qaf2GHXrl3mxKJNhciZ/mf9/fffzYk5MjKSOvRQx44dTd240vEJ2rqldBqs/mJzrUtt+t+8eTN1mYOEhAQz1kjHvznwefTc2bNnpUwZ91OAtiZoy6Hi81hwlStXNr8XT5w4IZ999pl0796deiwOVinjOmvJMVWzXr161hdffGGmakZFRZkF/zNy5Ejryy+/NFM0v/nmGys6OtqqWbOmmQarqEPPLwFQrlw5M+1Vp2i+9957VqVKlaxFixY599FpmtWqVbM+/PBD64cffrC6d+/ONM0cXLx40XzmdCZYVnwePTNgwADr8ssvd06/XrFihfl/PWrUKOc+fB49s3r1amvVqlXmkgqff/65meXZrl0769y5c2Y79Vi0Sn2Q0Q/SE088YVWvXt2cVO6++25zbQr8T9++fa3atWtbFSpUML/49LHrtU+oQ899/PHHVqtWrczUy2bNmllvvfWW23adqjlmzBgrLCzM7HPrrbdau3bt8ll5/ZVef0e/h+VUN3wePZOWlmZ+F2roCwoKsho2bGimC2dkZDj34fPomffff9/Un/6O1KnWQ4YMMVOsHajHohWgfxRL0w8AAICXlegxMgAAoGQjyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyADA/6d3ec965+z8REREyPTp0/PcJyAgwNypG4D3EWSAUkZPqnktL7zwgk/LltcJX2+0p/dSWrp0aY7bBw0aZG4SW1h9+/Y1978CYB/lfF0AAMXr6NGjzn+///77MnbsWLebWVapUqVAx9O7TVeoUEGKg96xXm8S+fbbb5u7Nrs6c+aMLFu2TOLj4wt1bL1bccWKFc0CwD5okQFKGb0Tr2MJCQkxrSCOxxoG9O7wGhg00Fx33XWydu3abF0pL730kjz44IMSHBwsgwcPNuvnzZsndevWlUqVKsndd98tU6dOzdZN8+GHH5oWk6CgIGnYsKGMHz9eLly44Dyu0udqmRyPc2p10TsJ6x2tXS1fvtwcS8u/evVq6dSpk3n90NBQufPOO80d2x0OHDhgXkOD3E033WTK895772XrWtLn6B2M86oPderUKbn33nvN3Y8vv/xymTVrVp4/g6SkJOnTp495rRo1apjX0DIBKDiCDACn06dPyx133GGCwvfffy9dunSRbt26ZQsNr776qlx11VVmnzFjxsg333wjjz32mDz99NOyY8cOue2222TixIluz/n6669N+NF9fvnlF3nzzTdNcHDst2XLFvN3QkKCaTVyPM5Ky6fBQp/rSp/Xs2dPEw40kI0YMUK2bt1q3kuZMmVMQMrMzHR7zujRo015fv31V4mJiSl0fUyZMsVZH45jrlmzJteWH32tqlWrmjrRutOQpMfW1i0ABVTEN6UE4McSEhKskJCQPPdp2bKl9frrrzsf169f3+rRo4fbPnpH9NjYWLd1/fv3dzu23vH35Zdfdtvn3XffNXdWd9BfSR988EG+5R49erTVoEEDc1dhpXdjDwgIsNauXZvj/sePHzfH/vHHH83j/fv3m8fTp0/3Sn106dIlW3107do1x/el77lp06bOsiu943TFihXNXb0BFAwtMgDcWiCeeeYZad68uWnZ0JYCba3I2gLRtm1bt8c6xub66693W5f18c6dO+XFF180x3QsjzzyiGl9OXv2bIHK+fDDD8v+/ftl/fr1ztYY7Yrq3Lmzebxnzx7T1aPdV9r95eimyu99FLY+oqKisj3W/XKi9bB3717TIuOoB+1eSk9Pd+v+AuAZBvsCcNKTtnaJaNdR48aNzcDXe+65J1uXh44FKSgNBTomRrt/stIxKgXRpEkTueGGG0yAufnmm2XhwoUmFOm4F6XdP/Xr1zfjdurUqWO6lFq1alXg9+FpfRS0HiIjI82YnKwuu+yyQh8XKK0IMgCcdLzGwIEDzXgSx0nXk0GoTZs2zTamJetjHeSrLTcaCHKjU6svXrzoUVl10O/jjz8ud911l/zxxx+m3OrPP/80r6MhRsOO2rhxoxRlfWzatCnbY23FyYnWgw4yrlWrlmktAnBp6FoC4NbSsWLFCjNgV7tA7rvvvmwDZHMydOhQ+de//mVmKmm3jg7kXbVqlbOFROk0b2050VaZn3/+2XS96PVgnn/+eec+2gWkA2uTk5PlxIkTeb5m7969TfB59NFH5fbbbzczplT16tXNTKW33nrLdOF88cUXZuBvUdaHBp7Jkyeba9DojCWdQaUDfnOis6pq1qxpZirpYF/tIvvyyy/lqaeeksOHDxeqnEBpRpAB4KRBRINAhw4dTPeMzq7x5AJzHTt2lLlz55rn6+wdnf48fPhwty4jPdYnn3win3/+uZnG3L59e5k2bZrpAnJ47bXXTFeOhpJrrrkmz9fUad56LRkNPDpmxkFnKGlA2rZtm+lO0nLorKKirI+RI0eaGVJa5gkTJpjn5TQLylHur776SurVq2e62bTlRluXdIwMLTRAwQXoiN9CPA8A8qRjVn777TfT6gAARYUxMgC8QgfE6vVjdACtdiu98847Mnv2bF8XC0AJR4sMAK/QK9XqWA+9yq1Oe9ZxM3qRPAAoSgQZAABgWwz2BQAAtkWQAQAAtkWQAQAAtkWQAQAAtkWQAQAAtkWQAQAAtkWQAQAAtkWQAQAAtkWQAQAAYlf/D4e1BFWM9rcUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#have a look at the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train.values, bins=50)\n",
    "plt.xlabel(\"Target Variable\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Target Variable\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b28cc",
   "metadata": {},
   "source": [
    "# 1. imputing missing values\n",
    "\n",
    "First we impute nan values with the mean for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5a23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan-values: 0\n",
      "              x0            x1           x2             x3          x4  \\\n",
      "id                                                                       \n",
      "0   14168.823171  10514.380717  3316.149698   94230.695124  102.386606   \n",
      "1   17757.037554  10950.160761  4101.016273   92959.527633  105.070358   \n",
      "2   14226.656663  11029.642499  3430.837498  124055.600561  100.542483   \n",
      "3    8766.012436   7384.202998  2147.308418  100157.719990  104.855061   \n",
      "4   13801.016418  13269.493652  3408.316953   92048.527786  103.759758   \n",
      "\n",
      "            x5            x6            x7            x8         x9  ...  \\\n",
      "id                                                                   ...   \n",
      "0    92.677127  11108.748199  10866.505510  10837.622093  10.227734  ...   \n",
      "1    99.855168  10013.959449  10826.607494  10076.101597  11.436970  ...   \n",
      "2    92.860892   9983.055476  10492.342868  10495.835570  10.810076  ...   \n",
      "3   101.929026  10050.049932  10499.521099  10525.030989  10.092109  ...   \n",
      "4    95.789235   9667.353978  10750.783106  10618.800750  12.006773  ...   \n",
      "\n",
      "            x822          x823        x824        x825        x826  \\\n",
      "id                                                                   \n",
      "0   10069.191241  12352.094085  846.014651  105.132144  102.112809   \n",
      "1   10069.191241  16198.071494  776.084467  106.385590  103.472030   \n",
      "2   10329.704431  13976.063780  737.040332  103.671234  109.458246   \n",
      "3   10008.251395   6212.127347  329.044233  105.084488  104.858546   \n",
      "4   10095.782015  13772.061493  812.316152  104.968652  100.369834   \n",
      "\n",
      "           x827      x828         x829         x830          x831  \n",
      "id                                                                 \n",
      "0   2090.004260  2.691845  1234.374109  1000.784475   9285.751272  \n",
      "1   2474.051881  2.287976  1359.981226  1012.626705  11750.284764  \n",
      "2   2656.083281  2.843706   888.353607  1048.810385   9553.922728  \n",
      "3   1097.785204  2.732257   927.752967  1048.357330   9981.085085  \n",
      "4   2693.053231  2.702908  1471.354073  1071.284484   9423.533063  \n",
      "\n",
      "[5 rows x 832 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(pd.Series(X_train.mean()), inplace=True)\n",
    "print(f\"Nan-values: {X_train.isna().sum().sum()}\")\n",
    "print(X_train.head())\n",
    "X_test.fillna(pd.Series(X_test.mean()), inplace=True)\n",
    "y_train.fillna(pd.Series(y_train.mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d4ae2",
   "metadata": {},
   "source": [
    "# 2. Outlier detection\n",
    "Next we build an outlier detection model to classify samples as outliers and eventually remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2064cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier indices: {np.int64(3), np.int64(515), np.int64(645), np.int64(900), np.int64(1031), np.int64(648), np.int64(906), np.int64(397), np.int64(917), np.int64(278), np.int64(24), np.int64(1048), np.int64(30), np.int64(416), np.int64(1056), np.int64(1058), np.int64(805), np.int64(167), np.int64(297), np.int64(681), np.int64(428), np.int64(306), np.int64(821), np.int64(694), np.int64(697), np.int64(953), np.int64(573), np.int64(190), np.int64(575), np.int64(64), np.int64(321), np.int64(448), np.int64(837), np.int64(70), np.int64(583), np.int64(75), np.int64(460), np.int64(972), np.int64(1102), np.int64(335), np.int64(474), np.int64(91), np.int64(731), np.int64(860), np.int64(991), np.int64(480), np.int64(225), np.int64(1120), np.int64(100), np.int64(229), np.int64(740), np.int64(231), np.int64(234), np.int64(362), np.int64(1137), np.int64(114), np.int64(882), np.int64(502), np.int64(1144), np.int64(506), np.int64(1150)}\n",
      "Number of outliers detected: 61\n"
     ]
    }
   ],
   "source": [
    "#outlier detection using isolation forest and guessing the contamination to be 5%\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "outlier_model = IsolationForest(contamination=0.05, random_state=42)\n",
    "outlier_model.fit(X_train)\n",
    "outlier_preds = outlier_model.predict(X_train)\n",
    "isoforest_outlier_indices = set(np.where(outlier_preds == -1)[0])\n",
    "\n",
    "print(\"Outlier indices:\", isoforest_outlier_indices)\n",
    "\n",
    "print(f\"Number of outliers detected: {len(isoforest_outlier_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac8194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Outlier indices: [  16   30   32   56   70   72   88   91  142  168  180  207  211  214\n",
      "  245  278  313  321  334  352  397  403  404  431  518  537  545  553\n",
      "  570  574  583  616  622  631  633  635  681  694  731  732  741  755\n",
      "  771  805  806  808  836  872  882  888  899  900  906  917  949  953\n",
      "  972  990  994 1001 1038 1066 1081 1087 1102 1132 1135 1144 1205]\n",
      "Number of outliers detected by SVM: 69\n",
      "Number of common outliers detected by both methods: 19\n",
      "Common outlier indices: {np.int64(900), np.int64(906), np.int64(397), np.int64(917), np.int64(278), np.int64(30), np.int64(805), np.int64(681), np.int64(694), np.int64(953), np.int64(321), np.int64(70), np.int64(583), np.int64(972), np.int64(1102), np.int64(731), np.int64(91), np.int64(882), np.int64(1144)}\n"
     ]
    }
   ],
   "source": [
    "# outlier detection using OneClassSVM\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "svm_model = OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=\"scale\")\n",
    "svm_model.fit(X_train_scaled)\n",
    "svm_preds = svm_model.predict(X_train_scaled)\n",
    "\n",
    "print(\"SVM Outlier indices:\", np.where(svm_preds == -1)[0])\n",
    "\n",
    "svm_outlier_indices = set(np.where(svm_preds == -1)[0])\n",
    "\n",
    "print(f\"Number of outliers detected by SVM: {np.sum(svm_preds == -1)}\")\n",
    "\n",
    "# Comparing the two methods\n",
    "common_outliers = isoforest_outlier_indices & svm_outlier_indices\n",
    "print(f\"Number of common outliers detected by both methods: {len(common_outliers)}\")\n",
    "print(\"Common outlier indices:\", common_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f5a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned X_train shape: (1193, 832), Cleaned y_train shape: (1193, 1)\n"
     ]
    }
   ],
   "source": [
    "#removing outliers from the training data\n",
    "X_train_cleaned = X_train.drop(index=X_train.index[list(common_outliers)])\n",
    "y_train_cleaned = y_train.drop(index=y_train.index[list(common_outliers)])\n",
    "print(f\"Cleaned X_train shape: {X_train_cleaned.shape}, Cleaned y_train shape: {y_train_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84833e4d",
   "metadata": {},
   "source": [
    "# 3. Feature selection\n",
    "In order to perform a useful regression we need to select features suitable for the age prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebc46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlation_matrix_reduction():\n",
    "    corr_matrix = X_train_cleaned.corr().abs()  # absolute value\n",
    "\n",
    "    # Mask upper triangle\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation > threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    print(\"Highly correlated features to drop:\", to_drop)\n",
    "    print(f\"Number of features to drop: {len(to_drop)}\")\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df4d015",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "this step is harder than imagined, a new idea came to my mind:\n",
    "\n",
    "1: select a subset of features randomly, train and score the predictions, as well as the features used\n",
    "\n",
    "2: do it for another subset\n",
    "\n",
    "3: mark the features which occur in higher scored subsets and use these for the final training (Monte Carlo aproach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6440cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subset_selector import RandomSubsetSelector\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "selector = RandomSubsetSelector(\n",
    "    estimator=XGBRegressor(\n",
    "        n_estimators=100,      # Number of trees; start low for speed in subset selection\n",
    "        max_depth=4,           # Tree depth; controls complexity\n",
    "        learning_rate=0.05,     # Step size; balances speed and accuracy\n",
    "        subsample=0.6,         # Fraction of samples per tree; adds randomness\n",
    "        colsample_bytree=0.6,  # Fraction of features per tree; helps with high-dimensional data\n",
    "        random_state=42,       # For reproducibility\n",
    "        n_jobs=-1              # Use all cores\n",
    "    ),\n",
    "    n_trials=1200,          # more trials → better coverage\n",
    "    subset_frac=0.02,\n",
    "    cv=4,\n",
    "    top_k=400,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    random_state=42,\n",
    "    max_samples=300,\n",
    ")\n",
    "load_cached = True\n",
    "\n",
    "filename = Path(\"feature_selection\") / \"random_subset_selector_features.csv\"\n",
    "if not load_cached:\n",
    "    X_selected = selector.fit_transform(X_train_cleaned, y_train_cleaned, feature_names=X_train_cleaned.columns)\n",
    "    with open(filename, \"w\") as f:\n",
    "        for feature in selector.selected_features_:\n",
    "            f.write(f\"{feature}\\n\")\n",
    "    print(\"\\n=== Top-10 most frequent features in best subsets ===\")\n",
    "    print(selector.summary.head(20))\n",
    "    print(f\"Selected feature set shape: {X_selected.shape}\")\n",
    "else:\n",
    "    with open(filename, \"r\") as f:\n",
    "        cols = [line.strip() for line in f.readlines()]\n",
    "    X_selected = X_train_cleaned[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f0ae5",
   "metadata": {},
   "source": [
    "# Main Task, fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b3e728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "activation = nn.Sigmoid\n",
    "\n",
    "# Define a simple MLP module\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units=128, num_layers=2, dropout=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = [nn.Linear(input_dim, hidden_units), activation(), nn.Dropout(dropout)]\n",
    "        for _ in range(1, num_layers):\n",
    "            layers.extend([nn.Linear(hidden_units, hidden_units), activation(), nn.Dropout(dropout)])\n",
    "        layers.append(nn.Linear(hidden_units, 1))  # Regression output\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c45a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training TorchNN...\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "→ TorchNN | CV R²: 0.4311 | Test R²: 0.4428 | Test MAE: 5.1363\n",
      "\n",
      "============================================================\n",
      "FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "  Model  Best R² (CV)  Train R²  Test R²  Test MAE\n",
      "TorchNN        0.4311    0.5286   0.4428    5.1363\n",
      "                                                                                                                                                                          Best Params\n",
      "{'model__optimizer__lr': 0.001, 'model__module__num_layers': 3, 'model__module__hidden_units': 128, 'model__module__dropout': 0.5, 'model__max_epochs': 400, 'model__batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# === MULTI-MODEL COMPARISON FOR BRAIN MRI AGE PREDICTION ===\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# --- 1. Split (keep X_selected from RandomSubsetSelector) ---\n",
    "X_train, X_t, y_train, y_t = train_test_split(\n",
    "    X_selected, y_train_cleaned, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(np.float32).values\n",
    "X_t = X_t.astype(np.float32).values\n",
    "y_train = y_train.astype(np.float32).values\n",
    "y_t = y_t.astype(np.float32).values\n",
    "\n",
    "# --- 2. CV Strategy ---\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "\n",
    "good_model = {\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBRegressor(random_state=35, n_jobs=-1),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [500],\n",
    "            \"model__max_depth\": [5,], \n",
    "            \"model__learning_rate\": [0.02],\n",
    "            \"model__subsample\": [0.8],\n",
    "            \"model__colsample_bytree\": [0.7],\n",
    "            \"model__gamma\": [1],\n",
    "            \"model__reg_alpha\": [0.1],\n",
    "        },\n",
    "        \"needs_scaling\": True\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Models & Hyperparameter Grids ---\n",
    "models = {\n",
    "    \"TorchNN\": {\n",
    "            \"model\": NeuralNetRegressor(\n",
    "                module=MLP,\n",
    "                module__input_dim=X_selected.shape[1],\n",
    "                criterion=nn.MSELoss,\n",
    "                optimizer=optim.Adam,\n",
    "                max_epochs=200,\n",
    "                batch_size=32,\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu',  # GPU if available\n",
    "                callbacks=[EarlyStopping(monitor='valid_loss', patience=30, threshold=0.0001)],\n",
    "                verbose=0,\n",
    "            ),\n",
    "            \"params\": {\n",
    "                \"model__module__hidden_units\": [32, 64, 128, 256, 512],  # Neurons per layer\n",
    "                \"model__module__num_layers\": [2, 3, ],         # Depth\n",
    "                \"model__module__dropout\": [0.3, 0.5, 0.7],      # Regularization\n",
    "                \"model__optimizer__lr\": [0.001, 0.005], # Learning rate\n",
    "                \"model__max_epochs\": [200, 400, 600, ],           # Training epochs\n",
    "                \"model__batch_size\": [16, 32]               # Batch size\n",
    "            },\n",
    "            \"needs_scaling\": True\n",
    "        },\n",
    "}\n",
    "\n",
    "# --- 4. Train & Compare ---\n",
    "results = []\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Build pipeline\n",
    "    steps = []\n",
    "    if config[\"needs_scaling\"]:\n",
    "        steps.append((\"scaler\", StandardScaler()))\n",
    "    steps.append((\"model\", config[\"model\"]))\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    # Grid search\n",
    "    gs = RandomizedSearchCV(\n",
    "        pipe, config[\"params\"], cv=cv, scoring=scorer, n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_train_pred = gs.predict(X_train)\n",
    "    y_test_pred = gs.predict(X_t)\n",
    "    \n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_t, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_t, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best R² (CV)\": gs.best_score_,\n",
    "        \"Train R²\": train_r2,\n",
    "        \"Test R²\": test_r2,\n",
    "        \"Test MAE\": test_mae,\n",
    "        \"Best Params\": gs.best_params_\n",
    "    })\n",
    "\n",
    "    print(f\"→ {name} | CV R²: {gs.best_score_:.4f} | Test R²: {test_r2:.4f} | Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# --- 5. Results Table ---\n",
    "results_df = pd.DataFrame(results).round(4)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results_df[[\"Model\", \"Best R² (CV)\", \"Train R²\", \"Test R²\", \"Test MAE\"]].to_string(index=False))\n",
    "print(results_df[[\"Best Params\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b33e9",
   "metadata": {},
   "source": [
    "# Train the model once again on the full dataset for the public test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_training(model):\n",
    "    params = results_df[[\"Best Params\"]].iloc[0].values[0]\n",
    "    print(params)\n",
    "    model = model(**params)\n",
    "    model.fit(X_selected, y_train_cleaned)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafaaf37",
   "metadata": {},
   "source": [
    "# Save the test results for online evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14764918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__learning_rate': 0.02, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\LRF\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [00:19:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"model__learning_rate\", \"model__max_depth\", \"model__n_estimators\", \"model__subsample\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved to results\\test_xgboost_20251030_001918.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kaggle competitions submit -c eth-aml-2025-project-1 -f submission.csv -m \"Message\"'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def save_test_predictions(model, model_name):\n",
    "    model = final_training(model)\n",
    "    save_path = results_dir / f\"test_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "    y_test_pred = model.predict(X_test[X_selected.columns])\n",
    "    results_df = pd.DataFrame(y_test_pred, index=X_test.index, columns=[\"y\"])\n",
    "    assert (results_df.shape == (776, 1)), f\"Unexpected shape: {results_df.shape}\"\n",
    "    results_df.to_csv(save_path)\n",
    "    print(f\"Test predictions saved to {save_path}\")\n",
    "\n",
    "save_test_predictions(XGBRegressor, \"xgboost\")\n",
    "\n",
    "'kaggle competitions submit -c eth-aml-2025-project-1 -f submission.csv -m \"Message\"'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LRF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
